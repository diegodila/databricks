30.1 qual é a arquitetura do databricks?
processamento distribuido e armazenamento distribuido

30.2 o que dbfs
databricks file system

30.3 o que é o databricks?
Uma plataforma aberta destinada para armazenar e gerenciar todos os seus dados para todas as suas cargas de dados
.. - O Azure Databricks é uma plataforma unificada de open analytics para criar, implantar, compartilhar e manter soluções de dados de nível empresarial, analytics e IA em escala. A Plataforma Azure Databricks Lakehouse integra-se ao armazenamento em nuvem e à segurança em sua conta de nuvem e gerencia e implanta a infraestrutura de nuvem em seu nome.

30.4 como é dividida a plataforma do databricks?
notebooks, analytics, delta lake, machine learning

30.5 o que é o delta lake?
Permite que sejam combinados os diversos tipos de dados inseridos no Databricks, pra que ajustes, tratamentos nos dados possam ser executados
..- Delta Lake is an open-source storage framework that enables building a
Lakehouse architecture with compute engines including Spark, PrestoDB, Flink, Trino, and Hive and APIs for Scala, Java, Rust, and Python.

30.6 A arquitetura da plataforma Azure Databricks é composta por duas partes principais, quais são?
A infraestrutura usada pelo Azure Databricks para implantar, configurar e gerenciar a plataforma e os serviços.
A infraestrutura de propriedade do cliente gerenciada em colaboração pelo Azure Databricks e sua empresa.

30.7 como funciona a migração de dados corporativos para AD?
..- o Azure Databricks não força você a migrar seus dados para sistemas de armazenamento proprietários para uso da plataforma
você configura um workspace do Azure Databricks configurando integrações seguras entre a plataforma do Azure Databricks e a conta de nuvem e, em seguida, o Azure Databricks implanta clusters de computação usando recursos de nuvem na conta para processar e armazenar dados no armazenamento de objetos e outros serviços integrados controlados por você

30.8 como funciona o catalogo Unity em relação aos dados corporativos?
..- Estende ainda mais essa relação, permitindo que você gerencie permissões para acessar dados usando a sintaxe SQL familiar no Azure Databricks.

30.9 o que é o delta live tables?
..- simplifica ainda mais o ETL, gerenciando de forma inteligente as dependências entre conjuntos de dados e implantando e dimensionando automaticamente a infraestrutura de produção para garantir a entrega oportuna e precisa dos dados de acordo com suas especificações

35.1 o que DBU?
databricks unity - is a unit processing capability per hour

35.2 como faço para acessar um arquivo do FileStore?
spark.read.load("/dbfs/FileStore/dados/iris.csv")

--featurestore

35.3 como é chamado no databricks quando dados brutos exigem pré-processamento e transformação antes que possam ser usados para criar um modelo.
engenharia de recursos

35.4 como sao chamadas as saidas de engenharia de recursos?
recursos. os blocos de construção do modelo.

--delta lake

36.1 what are data life cycle in databricks delta architecture?
bronze layer - raw ingestion, silver layer - (filtered, cleaned e augmented) - gold layer (bussiness-level aggregates)

36.2 What are the characteristic of the bronze layer in delta architecture
data lake - repository of raw data without schema enforcement
raw ingestion - raw data from multiple sources, long data retention
avoid error-prone parsing

36.3 what are the characteristic of the silver layer
apache spark data processing - (distributed cluster-computing framework - optimized for memory computation) filtered, cleaned and augmented 
intermediate data with cleanup queryable for easy debugging

36.4 which engine is spark, computing ou storage?
computing - data processing

36.5 what are the characteristic of the gold layer in delta architecture?
dw and olap - (analytics platform for enterprises - scalability - horizontally vs vertically) - bussiness-level aggregates
clean data, ready for consumption, dw-style (dimensions and fact)
apache hive and presto connectors

36.6 Can we bring several bronze tables to increase a silver table?
yes

36.7 Is ACID a feature the delta lake?
yes

36.8 what does ACID mean?
Atomicity, Consistency, Isolation, and Durability

37.8 how does delta lake writing work?
You can write data concurrently with integrity using something similar to the relational database, which is the transaction log

37.9 Within the delta lake framework, what writing models do I have?
optimistic concurrency model, where recordings are taking place and they are versioned and where we can guarantee transactions within a subsystem that is a storage

37.10 When I'm writing on a gigantic scale, what does Delta Lake use to scale the metadata?
it uses the power of the spark cluster to have scalable metadata

37.11 What is the possibility of returning an insert in delta lake called?
time travel - makes it possible to go back in time

37.12 Why is time travel in Delta Lake important?
for auditing, rollback, chat finger and reproducing machine learning experiments

37.13 What is schema evolution in delta lake?
maintains the current functionality of the data in the face of a change - if there is a change in the data source and a new column, your process does not break in the delta

37.14 What is audit history in delta lake?
stores all information for future audits

37.15 What is delete, update and merge statement in delta lake?
working with incremental data involves cdc and many insert, update and delete features and the merge statement feature is nothing more than if the data exists you update it if it doesn't exist you insert it 


---------------------------------------------------------------------------------------------------------------------------
Implementação do databricks

devemos criar um workspace com a featurestore?